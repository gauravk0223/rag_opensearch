{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "632176d5",
   "metadata": {},
   "source": [
    "### RAG implemenation with Symantic Chunking & OpenSearch as Vector Store (with hsnw index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f9ebb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the enviornment variables\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"HF_TOKEN\"]=os.getenv(\"HF_TOKEN\")\n",
    "os.environ[\"GOOGLE_API_KEY\"]=os.getenv(\"GOOGLE_API_KEY\")\n",
    "os.environ[\"OPENAI_API_KEY\"]=os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1dfb5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import Open AI embedding model used for symantic chunking & while convetring the chunks in vectors\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116539c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pdf document and create chunks using symantic chunking \n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "\n",
    "FILE_PATH=r\"C:\\Users\\gauravkkumar\\Documents\\2025\\rag\\data\\2407_01502v1.pdf\"\n",
    "loader=PyPDFLoader(FILE_PATH)\n",
    "pages = loader.load()\n",
    "\n",
    "text_splitter = SemanticChunker(embeddings)\n",
    "split_docs = text_splitter.split_documents(pages)\n",
    "\n",
    "print(split_docs[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4d71ec",
   "metadata": {},
   "source": [
    "### OpenSearch \n",
    "1. Create the client\n",
    "2. Create the index\n",
    "3. Create the OpenSearch vector store \n",
    "Pre-requiste: Make sure Opensearch is running in Docker locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d60361",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create OpenSearch Clinet \n",
    "from langchain_community.vectorstores import OpenSearchVectorSearch\n",
    "from opensearchpy import OpenSearch\n",
    "\n",
    "client = OpenSearch(\n",
    "    hosts=[{'host': 'localhost', 'port': 9200}],\n",
    "    http_auth=('admin', '<password>'),  # Replace with your credentials\n",
    "    use_ssl=True,\n",
    "    verify_certs=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7825eea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(embeddings.embed_query(\"Hello\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943ccdac",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create the index\n",
    "\n",
    "index_name = \"langchain-demo-index\"\n",
    "\n",
    "index_body = {\n",
    "    \"settings\": {\n",
    "        \"index\": {\n",
    "            \"knn\": True\n",
    "        }\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"text\": {\"type\": \"text\"},\n",
    "            \"vector_field\": {\n",
    "                \"type\": \"knn_vector\",\n",
    "                \"dimension\": 3072,  # Set to your embedding dimension\n",
    "                \"method\": {\n",
    "                    \"engine\": \"faiss\",  # or \"nmslib\" if desired\n",
    "                    \"space_type\": \"l2\",  # or \"cosinesimil\", etc.\n",
    "                    \"name\": \"hnsw\",      # or \"ivf\", \"flat\", etc. (see docs)\n",
    "                    \"parameters\": {\n",
    "                        \"ef_construction\": 512,\n",
    "                        \"m\": 16\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "if not client.indices.exists(index=index_name):\n",
    "    client.indices.create(index=index_name, body=index_body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d63b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "docsearch = OpenSearchVectorSearch(embedding_function=embeddings, \n",
    "                                   index_name=index_name,\n",
    "                                   opensearch_url=\"https://localhost:9200\", \n",
    "                                    http_auth=(\"admin\", \"<password>\"),\n",
    "                                    use_ssl = True,\n",
    "                                    verify_certs = False, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9418d04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from uuid import uuid4\n",
    "uuids = [str(uuid4()) for _ in range(len(split_docs))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a314ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "docsearch.add_documents(documents=split_docs, ids=uuids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea94572",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = client.count(index=index_name)['count']\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9682355",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = docsearch.similarity_search(\"What is agentic AI?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9320e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42136cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever=docsearch.as_retriever(\n",
    "    search_type=\"similarity_score_threshold\",\n",
    "    search_kwargs={\"k\": 3, \"score_threshold\": 0.3} #hyperparameter\n",
    ")\n",
    "retriever.invoke(\"What is LangChain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838a63aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "model=ChatGroq(model=\"gemma2-9b-it\")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696253d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aec5728",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908791ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e426e5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_chain.invoke(\"what is Agentic AI?\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
